{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§ù LinkedIn Professional Match - Getting Started\n",
        "\n",
        "Welcome to the LinkedIn Professional Match dataset! This notebook will help you:\n",
        "- üìä Explore the dataset\n",
        "- ü§ñ Load and use the pre-trained model\n",
        "- üéØ Make compatibility predictions\n",
        "- üí° Discover contribution opportunities\n",
        "\n",
        "## üåü Project Overview\n",
        "\n",
        "This is an **open-source ML system** for predicting professional networking compatibility on LinkedIn.\n",
        "\n",
        "**What's included:**\n",
        "- 50K+ synthetic professional profiles\n",
        "- 500K+ compatibility pairs with scores\n",
        "- Pre-trained Gradient Boosting model (R¬≤=1.0)\n",
        "- 18 engineered features with explainable AI\n",
        "\n",
        "**GitHub:** https://github.com/Likitha-Gedipudi/LinkedIn_Match_Algorithm\n",
        "\n",
        "**Live API:** https://linkedin-match-algorithm-4ce8d98dc007.herokuapp.com\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "\n",
        "# Visualization settings\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette('husl')\n",
        "\n",
        "print('‚úÖ Libraries loaded!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Part 1: Dataset Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load profiles dataset\n",
        "profiles = pd.read_csv('profiles_enhanced.csv')\n",
        "\n",
        "print(f'Profiles Dataset Shape: {profiles.shape}')\n",
        "print(f'Total Profiles: {len(profiles):,}')\n",
        "print(f'Features: {profiles.shape[1]}')\n",
        "print(f'\\nMemory Usage: {profiles.memory_usage(deep=True).sum() / 1024**2:.1f} MB')\n",
        "\n",
        "profiles.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load compatibility pairs\n",
        "pairs = pd.read_csv('compatibility_pairs_enhanced.csv')\n",
        "\n",
        "print(f'Pairs Dataset Shape: {pairs.shape}')\n",
        "print(f'Total Pairs: {len(pairs):,}')\n",
        "print(f'Features: {pairs.shape[1]}')\n",
        "\n",
        "pairs.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Part 2: Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Profile statistics\n",
        "print('=== Profile Statistics ===')\n",
        "print(f\"\\nAverage Connections: {profiles['connections'].mean():.0f}\")\n",
        "print(f\"Average Skills: {profiles['skills'].str.split(',').str.len().mean():.1f}\")\n",
        "print(f\"Average Experience Years: {profiles['experience_years'].mean():.1f}\")\n",
        "\n",
        "# Visualize distributions\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Connections distribution\n",
        "axes[0, 0].hist(profiles['connections'], bins=50, edgecolor='black')\n",
        "axes[0, 0].set_title('Connections Distribution')\n",
        "axes[0, 0].set_xlabel('Number of Connections')\n",
        "\n",
        "# Experience years\n",
        "axes[0, 1].hist(profiles['experience_years'], bins=30, edgecolor='black', color='orange')\n",
        "axes[0, 1].set_title('Experience Years Distribution')\n",
        "axes[0, 1].set_xlabel('Years')\n",
        "\n",
        "# Top industries\n",
        "top_industries = profiles['industry'].value_counts().head(10)\n",
        "axes[1, 0].barh(top_industries.index, top_industries.values)\n",
        "axes[1, 0].set_title('Top 10 Industries')\n",
        "axes[1, 0].set_xlabel('Count')\n",
        "\n",
        "# Top locations\n",
        "top_locations = profiles['location'].value_counts().head(10)\n",
        "axes[1, 1].barh(top_locations.index, top_locations.values, color='green')\n",
        "axes[1, 1].set_title('Top 10 Locations')\n",
        "axes[1, 1].set_xlabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compatibility score distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].hist(pairs['compatibility_score'], bins=50, edgecolor='black', color='purple')\n",
        "axes[0].set_title('Compatibility Score Distribution')\n",
        "axes[0].set_xlabel('Score (0-100)')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].axvline(pairs['compatibility_score'].mean(), color='red', linestyle='--', label='Mean')\n",
        "axes[0].legend()\n",
        "\n",
        "# Score by recommendation\n",
        "recommendation_counts = pairs['recommendation'].value_counts()\n",
        "axes[1].bar(recommendation_counts.index, recommendation_counts.values, color=['green', 'blue', 'orange', 'red'])\n",
        "axes[1].set_title('Recommendations Distribution')\n",
        "axes[1].set_xlabel('Recommendation')\n",
        "axes[1].set_ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nAverage Compatibility Score: {pairs['compatibility_score'].mean():.2f}\")\n",
        "print(f\"Median: {pairs['compatibility_score'].median():.2f}\")\n",
        "print(f\"Std Dev: {pairs['compatibility_score'].std():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§ñ Part 3: Load Pre-trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the trained model\n",
        "model_data = joblib.load('compatibility_scorer.joblib')\n",
        "\n",
        "pipeline = model_data['pipeline']\n",
        "feature_names = model_data['feature_names']\n",
        "model_type = model_data['model_type']\n",
        "\n",
        "print(f'‚úÖ Model loaded successfully!')\n",
        "print(f'Model Type: {model_type}')\n",
        "print(f'Features: {len(feature_names)}')\n",
        "print(f'\\nFeature Names:')\n",
        "for i, feat in enumerate(feature_names, 1):\n",
        "    print(f'  {i}. {feat}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Part 4: Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare test data\n",
        "X_test = pairs[feature_names].head(100)\n",
        "y_test = pairs['compatibility_score'].head(100)\n",
        "\n",
        "# Make predictions\n",
        "predictions = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
        "r2 = r2_score(y_test, predictions)\n",
        "\n",
        "print('=== Model Performance ===')\n",
        "print(f'MAE: {mae:.3f}')\n",
        "print(f'RMSE: {rmse:.3f}')\n",
        "print(f'R¬≤ Score: {r2:.3f}')\n",
        "\n",
        "# Visualize predictions vs actual\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test, predictions, alpha=0.6)\n",
        "plt.plot([0, 100], [0, 100], 'r--', label='Perfect Prediction')\n",
        "plt.xlabel('Actual Score')\n",
        "plt.ylabel('Predicted Score')\n",
        "plt.title('Predictions vs Actual')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Predict compatibility for a custom profile pair\n",
        "custom_features = pd.DataFrame([{\n",
        "    'skill_match_score': 75,\n",
        "    'skill_complementarity_score': 85,\n",
        "    'network_value_a_to_b': 60,\n",
        "    'network_value_b_to_a': 65,\n",
        "    'career_alignment_score': 70,\n",
        "    'experience_gap': 5,\n",
        "    'industry_match': 80,\n",
        "    'geographic_score': 90,\n",
        "    'seniority_match': 75,\n",
        "    'network_value_avg': 62.5,\n",
        "    'network_value_diff': 5,\n",
        "    'skill_total': 160,\n",
        "    'skill_balance': 63.75,\n",
        "    'exp_gap_squared': 25,\n",
        "    'is_mentorship_gap': 1,\n",
        "    'is_peer': 0,\n",
        "    'skill_x_network': 53.125,\n",
        "    'career_x_industry': 56.0\n",
        "}])\n",
        "\n",
        "score = pipeline.predict(custom_features)[0]\n",
        "print(f'\\nüéØ Predicted Compatibility Score: {score:.1f}/100')\n",
        "\n",
        "if score >= 80:\n",
        "    print('‚úÖ Recommendation: Highly Compatible - Strong mutual benefit expected!')\n",
        "elif score >= 60:\n",
        "    print('‚úÖ Recommendation: Good Match - Potential for valuable connection')\n",
        "elif score >= 40:\n",
        "    print('‚ö†Ô∏è Recommendation: Moderate Match - Some synergies present')\n",
        "else:\n",
        "    print('‚ùå Recommendation: Low Match - Limited mutual benefit')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üí° Part 5: Contribution Ideas\n",
        "\n",
        "### üöÄ How You Can Contribute\n",
        "\n",
        "This is an **open-source project** and we welcome contributions! Here are some ideas:\n",
        "\n",
        "#### üéØ Beginner-Friendly\n",
        "1. **Data Analysis** - Create visualizations and insights from the dataset\n",
        "2. **Feature Engineering** - Add new compatibility features\n",
        "3. **Documentation** - Improve README, add tutorials\n",
        "4. **Bug Reports** - Find and report issues\n",
        "\n",
        "#### üî• Intermediate\n",
        "5. **Model Improvements** - Try different algorithms (Neural Networks, LightGBM)\n",
        "6. **Hyperparameter Tuning** - Optimize model performance\n",
        "7. **New Features** - Add conversation starters, red flags detection\n",
        "8. **API Enhancements** - Add caching, rate limiting, authentication\n",
        "\n",
        "#### üöÄ Advanced\n",
        "9. **Deep Learning** - Build transformer-based models\n",
        "10. **Real Data Integration** - Connect to real LinkedIn API (ethically)\n",
        "11. **Web Dashboard** - Build React/Streamlit interface\n",
        "12. **Graph Neural Networks** - Use network structure for predictions\n",
        "13. **Explainable AI** - Add SHAP/LIME interpretability\n",
        "14. **A/B Testing Framework** - Compare model versions\n",
        "\n",
        "### üìù How to Contribute\n",
        "\n",
        "1. **Fork** the GitHub repo: https://github.com/Likitha-Gedipudi/LinkedIn_Match_Algorithm\n",
        "2. **Clone** your fork: `git clone <your-fork-url>`\n",
        "3. **Create branch**: `git checkout -b feature/amazing-feature`\n",
        "4. **Make changes** and commit: `git commit -m 'Add amazing feature'`\n",
        "5. **Push**: `git push origin feature/amazing-feature`\n",
        "6. **Open Pull Request** on GitHub\n",
        "\n",
        "### üèÜ Recognition\n",
        "\n",
        "All contributors will be:\n",
        "- Listed in CONTRIBUTORS.md\n",
        "- Credited in release notes\n",
        "- Acknowledged in README\n",
        "\n",
        "---\n",
        "\n",
        "## üåê Resources\n",
        "\n",
        "- **GitHub Repository**: https://github.com/Likitha-Gedipudi/LinkedIn_Match_Algorithm\n",
        "- **Live API**: https://linkedin-match-algorithm-4ce8d98dc007.herokuapp.com\n",
        "- **Chrome Extension**: [Link to extension folder]\n",
        "- **Documentation**: [Link to docs]\n",
        "\n",
        "## üìß Contact\n",
        "\n",
        "- Questions? Open an issue on GitHub\n",
        "- Suggestions? Start a discussion\n",
        "- Want to collaborate? Reach out!\n",
        "\n",
        "---\n",
        "\n",
        "**Happy coding! üöÄ**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance (if using tree-based model)\n",
        "try:\n",
        "    regressor = pipeline.named_steps['regressor']\n",
        "    if hasattr(regressor, 'feature_importances_'):\n",
        "        importance_df = pd.DataFrame({\n",
        "            'feature': feature_names,\n",
        "            'importance': regressor.feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "        \n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.barh(importance_df['feature'], importance_df['importance'])\n",
        "        plt.xlabel('Importance')\n",
        "        plt.title('Feature Importance')\n",
        "        plt.gca().invert_yaxis()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        print('\\nTop 5 Most Important Features:')\n",
        "        print(importance_df.head())\n",
        "except Exception as e:\n",
        "    print(f'Feature importance not available: {e}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
